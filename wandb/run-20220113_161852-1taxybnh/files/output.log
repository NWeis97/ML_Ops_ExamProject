Loading data...
Loading data and splitting training and validation set...
Loading model...
Loading configuration...
Loading model...
/Users/frederikhartmann/Desktop/3. Semester/Januar MLOPS/ML_Ops_ExamProject/src/data/make_dataset.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.encodings = {key: torch.tensor(val) for key, val in encodings.items()}
/Users/frederikhartmann/Desktop/3. Semester/Januar MLOPS/ML_Ops_ExamProject/src/data/make_dataset.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.labels = torch.tensor(labels)
Setting up optimizer...
Setting up scheduler...
Training model...
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|                                                                                                                          | 0/8 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/Users/frederikhartmann/Desktop/3. Semester/Januar MLOPS/ML_Ops_ExamProject/src/models/train_model.py", line 423, in <module>
    run()
  File "/Users/frederikhartmann/Desktop/3. Semester/Januar MLOPS/ML_Ops_ExamProject/src/models/train_model.py", line 390, in run
    train_loss, train_acc = train(model,
  File "/Users/frederikhartmann/Desktop/3. Semester/Januar MLOPS/ML_Ops_ExamProject/src/models/train_model.py", line 224, in train
    outputs = model(**batch)
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1370, in forward
    transformer_outputs = self.transformer(
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 887, in forward
    outputs = block(
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 395, in forward
    attn_outputs = self.attn(
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 317, in forward
    query, key, value = self.c_attn(hidden_states).split(self.split_size, dim=2)
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/frederikhartmann/opt/anaconda3/envs/Py39_MLOps/lib/python3.9/site-packages/transformers/modeling_utils.py", line 1766, in forward
    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)
KeyboardInterrupt